import numpy as np
import pandas as pd
import tensorflow as pd_tf # åˆ«åå¤„ç†
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

# --- 1. åŠ è½½å¹¶å¢å¼ºæ•°æ® ---
print("æ­£åœ¨å¤„ç†æ•°æ®...")
df = pd.read_csv('btc_history_2y.csv')

# ç‰¹å¾å·¥ç¨‹ï¼šæ·»åŠ æŠ€æœ¯æŒ‡æ ‡
# AI éœ€è¦çœ‹åˆ°è¶‹åŠ¿ï¼Œä¸ä»…ä»…æ˜¯ä»·æ ¼
df['SMA_15'] = df['close'].rolling(window=15).mean()
df['SMA_60'] = df['close'].rolling(window=60).mean()
df['Vol_Change'] = df['volume'].pct_change()

# RSI è®¡ç®—
delta = df['close'].diff()
gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
rs = gain / loss
df['RSI'] = 100 - (100 / (1 + rs))

df.dropna(inplace=True) # å»é™¤è®¡ç®—äº§ç”Ÿçš„ç©ºå€¼

# --- 2. å®šä¹‰ç›®æ ‡ ---
# ç›®æ ‡ï¼šé¢„æµ‹ä¸‹ä¸€ä¸ªå°æ—¶æ”¶ç›˜ä»·æ˜¯æ¶¨(1) è¿˜æ˜¯ è·Œ(0)
df['Target'] = (df['close'].shift(-1) > df['close']).astype(int)

# é€‰å– AI çš„è¾“å…¥ç‰¹å¾
features = ['close', 'volume', 'SMA_15', 'SMA_60', 'RSI', 'Vol_Change']
data = df[features].values
target = df['Target'].values

# --- 3. æ•°æ®å½’ä¸€åŒ– (éå¸¸é‡è¦) ---
scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data)

# --- 4. æ„å»ºæ—¶é—´åºåˆ—æ•°æ® (Sliding Window) ---
# LSTM éœ€è¦çœ‹åˆ°å†å²ç‰‡æ®µã€‚æˆ‘ä»¬è®¾å®š lookback=60
# æ„æ€æ˜¯ç”¨ è¿‡å»60å°æ—¶çš„æ•°æ® -> é¢„æµ‹ ç¬¬61å°æ—¶çš„æ¶¨è·Œ
X = []
y = []
lookback = 60

for i in range(lookback, len(data_scaled)):
    X.append(data_scaled[i-lookback:i]) # è¿‡å»60è¡Œæ‰€æœ‰ç‰¹å¾
    y.append(target[i]) # ç¬¬iè¡Œçš„ç›®æ ‡

X, y = np.array(X), np.array(y)

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† (å‰80%è®­ç»ƒï¼Œå20%éªŒè¯)
split = int(len(X) * 0.8)
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

print(f"æ„å»ºå®Œæˆï¼šè®­ç»ƒæ ·æœ¬ {X_train.shape[0]}, æµ‹è¯•æ ·æœ¬ {X_test.shape[0]}")

# --- 5. æ­å»º LSTM æ¨¡å‹ ---
model = Sequential()

# ç¬¬ä¸€å±‚ LSTM
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dropout(0.2)) # ä¸¢å¼ƒ20%ç¥ç»å…ƒé˜²æ­¢è¿‡æ‹Ÿåˆ

# ç¬¬äºŒå±‚ LSTM
model.add(LSTM(units=50, return_sequences=False))
model.add(Dropout(0.2))

# è¾“å‡ºå±‚ (Sigmoid æ¿€æ´»å‡½æ•°ç”¨äºè¾“å‡º 0-1 ä¹‹é—´çš„æ¦‚ç‡)
model.add(Dense(units=1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# --- 6. å¼€å§‹è®­ç»ƒ ---
print("ğŸš€ å¼€å§‹è®­ç»ƒç¥ç»ç½‘ç»œ (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
# epochs=20 (å­¦20é), batch_size=32 (æ¯æ¬¡å­¦32ä¸ªæ ·æœ¬)
history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))

# --- 7. è¯„ä¼°ç»“æœ ---
print("\n" + "="*30)
loss, accuracy = model.evaluate(X_test, y_test)
print(f"æœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.2%}")
print("="*30)

# --- 8. ç®€å•çš„å®æˆ˜æ¨¡æ‹Ÿ ---
# è·å–æ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡
predictions = model.predict(X_test)
# å¦‚æœæ¦‚ç‡ > 0.5 åˆ¤ä¸ºæ¶¨ï¼Œå¦åˆ™åˆ¤ä¸ºè·Œ
pred_labels = (predictions > 0.5).astype(int).flatten()

# åªæ˜¯ä¸ºäº†çœ‹æœ€åå‡ æ¡çš„é¢„æµ‹æƒ…å†µ
result_df = pd.DataFrame({'Actual': y_test[-10:], 'Predicted': pred_labels[-10:], 'Prob': predictions[-10:].flatten()})
print("\næœ€å 10 ä¸ªå°æ—¶çš„é¢„æµ‹å¯¹æ¯” (Actual:1æ¶¨0è·Œ):")
print(result_df)